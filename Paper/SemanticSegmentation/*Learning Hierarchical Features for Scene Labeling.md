# 基本情况
这是PAMI2013的一篇文章，作者是LeCun等人，所属领域是Image Segmentation.感觉本篇文章比较难读懂.  

# Abstract
本文提出了一种使用从原始像素训练的多尺度卷积网络提取密集特征向量的方法，该特征向量编码以每个像素为中心的多个尺寸的区域.该方法减轻了对工程特征的需求，并且产生了一种强大的表示，可以捕获纹理，形状和上下文信息.本文使用多种后处理方法报告结果以生成最终标签.其中，本文提出了一种技术，可以从分割组件池自动检索最佳解释场景的最佳组件集合;这些组分是任意的，例如它们可以从分割树中获取，或从任何超分割系列中获取.该系统在Sift Flow Dataset（33个类别）和 Barcelona DataSet （170个类别）打破了记录和在Stanford Background Dataset（8个类别）接近记录，同时比竞争方法快一个数量级，产生320 ×240图像标签不到一秒钟，包括特征提取.  

# Instroduction
**两个问题**  
在场景解析的背景下，有两个主要的重要问题：如何产生视觉信息的良好内部表示，以及如何使用上下文信息来确保解释的自我一致性.  本文的主要使用深度学习的方法解决上述的两个问题，主要想法是在一个大输入窗口上使用卷积网络操作产生每个像素位置的标签预测.卷积神经网络本身通过多个阶段的卷积、非线性激活、空间pooling来实现end-to-end的训练，从而自动学习分级特征表示.  
但是，通过一个小的区域（卷积核大小）来标注每个像素比较困难.因为，一个像素的分类可能有的时候依赖于相对short-range的信息，例如人脸的存在可能暗示人身体的存在；来有的时候需要依赖long-range的信息，确定一个像素属于公路需要大范围的信息；为了解决这个问题，本文提出了使用multi-scale卷积神经网络.  
<br/>  
经典的分割方法一般是先使用基于图的方法产生分割的proposal.然后使用engineered特征进行对候选分割区域的编码.最后使用CRF或者其他的图模型来产生每个候选分割的标签，同时保证标签的全局一致性.本文通过大的上下文窗口可以不使用复杂的后处理且能确保标签一致性.  
本文提出的方法架构如下图所示:  
![1](http://i2.muimg.com/589172/8e4a7500e8eaa566.png)  
上述架构主要由两部分组成:  
(1)Multi-scale卷积表示.不同的尺寸对应的网络是权值共享的，其实是同一个网络的copy，输入的图片是输入图片的Laplacian pyramid的不同尺寸.这种方法可以被学习被高效的进行场景中的物体和区域的检测和识别，但是无法找到区域的精确边界，因此需要后处理来勾勒.  
(2)Graph-based classification.  
考虑了三种方法来产生最终的图片标注:1.Superpixels.通过在卷积特征向量上训练pixelwise分类器，使用简单的投票方法来指定每一个superpixles的标签.这种方法是fixed-level，因此效果不太理想.(2)CRF over superpixels.在superpixel基础上使用CRF，避免local aberrations畸变.但是这种对本文来时不是必须的，因为multiscale feature使得大多数的scene-level关系已经被捕捉到了.(3)Multilevel cut with class purity criterion.也就是使用一族的方法方法进行分割,比如同一方法使用不同参数等.本文采用的应该就是这种方法.  
<br/>
剩下的部分没有看得太懂，暂时先不进行介绍.  
