要谈mAP必须先说一下，精准率(Precision， P值)和召回率(Recall，R值).P值和R值最初是信息检索领域的评价指标.  
# 准确率Accuracy
这个概念是指分类的准确率，也就是分类准确的样本与样本总数之比.  
```
举个例子：
假设一个样本集中有100个样本，其中99个负样本，1个正样本.
```  
碰巧某个分类器的原理就是所有样本均判为负，那个这个分类器的accuracy就是99%.这比很多算法厉害的分类器都厉害.但是仔细想想，如果总样本中只有1个负样本但是有99个正样本，那个这个分类器，那个这个分类器的正确率将是1%.  
由此可以发现，accuracy的值与样本集中正负样本的比例关系很大.通常情况下，我们希望的算法是在不同场景下表现都比较好的算法，也就是泛化能力强的算法，显然accuracy并不能作为算法泛化能力的衡量. 

# P值和R值和F值
Precision中文可以翻译为“查准率”（有时候也翻译为“准确率”），也就是返回的结果中希望得到的结果所占的比例.  
Recall中文可以翻译为“查全率”或者通常说的“召回率”，也就是返回的结果希望得到的结果占总样本中所有希望的得到的结果的比例.  
这两个值都是标量，需要进行计算.数学通常希望把一个概念数字化，于是想想一种场景:比如一个搜索引擎中共有n条数据，关于“图像语义分割”的数据有m条，经过搜索，返回了k条.这k条中有一部分是和“图像语义分割”相关的，也有一部分不是.于是就有了以下几个量:  
![1](http://i2.muimg.com/589172/211ad894d9b5912d.png)  
很容易可以看出，P值和R值的值应该等于：  
![img](http://i2.muimg.com/589172/99d7798fabf494a3.png)  
简单理解一下，其实P值就是找的准，R值就是找的全.理想情况下如果以R值为横坐标，P值就一直为1.这样两者的乘积就是1.(其实这种图就是P-R图，可能有的人不太理解里边的原理，下边会说).但是实际中
往往P值和R值是矛盾的.比如，把所有结果都返回，则R值为100%，但是此时P值就很小；如果只取一个结果且是期望的，那么P值为100%，但是此时显然没有选出全部的（R值很小）.  
通常情况下，对于一个模型的P值和R值需要综合考虑（为什么？既然提出来了两个，肯定都要考虑一下了，就像山就在那里）.这个时候就引出了 **F-measure** ，也就是F值.
![1](http://i2.muimg.com/589172/80d2c6bd6d8323fc.png)  
关于F值这里就不多说了，其中参数beta是根据不同的场景进行调节的.更常用的是F1度量:  
![1](http://i2.muimg.com/589172/41950d0c5054bcbe.png)  

# mAP
本文是要讲mAP的，终于前面铺垫了这么多，可以开始讲mAP了.但是，为了讲述mAP，这里还需要先说一下如何画P-R图.  
**P-R图**：制定一个类别，根据学习器下每个样本对这个类的预测结果进行排序，排在前面的是学习器认为“最可能”的正例样本，最后的是“最不可能的”.按照此顺序逐个把样本作为正例进行预测（1个正例，2个正例，...），则每次可以计算出当前的R值和P值，然后以R值为横轴、P值为纵轴记性作图.就得到了P-R图.  
![1](http://i1.piimg.com/589172/71a074d3c02e52b2.png)  
应该比较容易想到B系统比C系统在这个场景下表现好(自己想想为什么).  
为了能够量化分类器的性能比较，通常采用Average Precison来作为度量标准，公式为:  
![1](http://i1.piimg.com/589172/aaa973606eb7fbc7.png)  
上式给出的一种积分的形式，实际上P-R图中的值是离散值，化为sum即可.  
而mAP是对所有类别的AP值的平均，也就是所有的AP值求和除以类数.顺便说一句，average是也就是对recall取平均的，mean是对类取平均.  
现在的图像分类论文基本都是用mAP作为标准，PASCALVOC的多个屏幕项目也都是使用mAP作为标准的.  
